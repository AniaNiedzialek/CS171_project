{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import ResNet18_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_name = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_name = \"mps\"\n",
    "else:\n",
    "    device_name = \"cpu\"\n",
    "    \n",
    "print(f'Using device: {device_name}')\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "**Load and Prepare Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels\n",
    "labels = pd.read_csv(\"../data/labels.csv\")\n",
    "\n",
    "image_paths = []\n",
    "pattern_labels = []\n",
    "division_labels = []\n",
    "\n",
    "for idx, row in labels.iterrows():\n",
    "    folder = f\"../data/frames/{row['division']}/{row['division']}_{row['id']}\"\n",
    "    for img_path in Path(folder).glob(\"*.jpg\"):\n",
    "        image_paths.append(str(img_path))\n",
    "        pattern_labels.append(row['pattern'])\n",
    "        division_labels.append(row['division'])\n",
    "\n",
    "# Load image\n",
    "img = Image.open(image_paths[0]).convert(\"RGB\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "**Build Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_model(num_classes: int):\n",
    "    # model = models.resnet18(pretrained=True)\n",
    "    # in_features = model.fc.in_features\n",
    "    # model.fc = nn.Linear(in_features, num_classes)\n",
    "    # return model\n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "**Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = sorted(set(pattern_labels))\n",
    "label2id = {p:i for i,p in enumerate(patterns)}\n",
    "y = np.array([label2id[p] for p in pattern_labels], dtype=np.int64)\n",
    "\n",
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, paths, labels, tfm):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.tfm = tfm\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    def __getitem__(self, i):\n",
    "        path = self.paths[i]               \n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        return self.tfm(img), self.labels[i]\n",
    "tfm = build_transforms()\n",
    "full_dataset = FrameDataset(image_paths, y, tfm)\n",
    "\n",
    "# train and test loaders and splits\n",
    "g = torch.Generator().manual_seed(42)\n",
    "n = len(full_dataset)\n",
    "n_train = int(0.8*n)\n",
    "n_test = n - n_train\n",
    "train_ds, test_ds = random_split(full_dataset, [n_train, n_test], generator=g)\n",
    "\n",
    "pin = (device.type == \"cuda\")  # pin_memory only helps on CUDA\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,\n",
    "                          num_workers=0, pin_memory=pin, persistent_workers=False)\n",
    "test_loader   = DataLoader(test_ds,   batch_size=32, shuffle=False,\n",
    "                          num_workers=0, pin_memory=pin, persistent_workers=False)\n",
    "\n",
    "len(train_ds), len(test_ds), len(patterns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(patterns)\n",
    "model = build_resnet_model(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Train and Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, train=True):\n",
    "    model.train(train)\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * yb.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    return total_loss / max(total,1), correct / max(total,1)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss, train_acc = run_epoch(train_loader, train=True)\n",
    "    test_loss, test_acc = run_epoch(test_loader,   train=False)\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"train loss {train_loss:.4f} acc {train_acc:.3f} | \"\n",
    "          f\"val loss {test_loss:.4f} acc {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "torch.save(\n",
    "    {\"state_dict\": model.state_dict(),\n",
    "    \"label2id\":label2id,\n",
    "    \"id2label\":{v:k for k,v in label2id.items()}},\n",
    "    \"models/resnet_pattern_classifier.pth\"\n",
    ")\n",
    "print(\"Saved model to models/resnet18_pattern.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"models/resnet_pattern_classifier.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)   \n",
    "\n",
    "num_classes = len(ckpt[\"label2id\"])\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])           \n",
    "model = model.to(device).eval()\n",
    "\n",
    "id2label = {v:k for k,v in checkpoint[\"label2id\"].items()}\n",
    "print(\"Loaded classes:\", id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = build_transforms()\n",
    "test_img_path = image_paths[0]  \n",
    "img = Image.open(test_img_path).convert(\"RGB\")\n",
    "x = tfm(img).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(x)\n",
    "pred_id = logits.argmax(1).item()\n",
    "print(\"Prediction:\", id2label[pred_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs)",
   "language": "python",
   "name": "cs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
